{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Indonesian SMS Data (Traditional ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IDSMSA.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check class distribution\n",
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and map sentiment labels\n",
    "df.dropna(subset=['Sentiment'], inplace=True)\n",
    "df['Sentiment'] = df['Sentiment'].str.lower().str.strip()\n",
    "label_map = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "df['label'] = df['Sentiment'].map(label_map)\n",
    "df.dropna(subset=['label'], inplace=True)\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Sentence'], \n",
    "    df['label'], \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=df['label']\n",
    ")\n",
    "\n",
    "print(f'Train set size: {len(X_train)}')\n",
    "print(f'Test set size: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Traditional ML Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Indonesian Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "stopword_factory = StopWordRemoverFactory()\n",
    "stopword_remover = stopword_factory.create_stop_word_remover()\n",
    "\n",
    "def preprocess_text(text, use_stopwords=True, use_stemming=True):\n",
    "    text = text.lower()\n",
    "    if use_stopwords:\n",
    "        text = stopword_remover.remove(text)\n",
    "    if use_stemming:\n",
    "        text = stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Advanced Indonesian Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More comprehensive stopword list\n",
    "stopword_list = nltk.corpus.stopwords.words('indonesian')\n",
    "\n",
    "def convert_emoticons(text):\n",
    "    for emot in EMOTICONS_EMO:\n",
    "        text = text.replace(emot, '_'.join(EMOTICONS_EMO[emot].replace(',', '').split()))\n",
    "    return text\n",
    "\n",
    "def preprocess_text_advanced(text, use_stopwords=True, use_stemming=True):\n",
    "    text = convert_emoticons(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s_]', '', text) # Remove punctuation and special chars\n",
    "    tokens = word_tokenize(text)\n",
    "    if use_stopwords:\n",
    "        tokens = [word for word in tokens if word not in stopword_list]\n",
    "    text = ' '.join(tokens)\n",
    "    if use_stemming:\n",
    "        text = stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. TF-IDF Vectorization and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_options = {\n",
    "    'Stemming + Stopwords (Sastrawi)': lambda x: preprocess_text(x, use_stopwords=True, use_stemming=True),\n",
    "    'Stemming Only (Sastrawi)': lambda x: preprocess_text(x, use_stopwords=False, use_stemming=True),\n",
    "    'Stopwords Only (Sastrawi)': lambda x: preprocess_text(x, use_stopwords=True, use_stemming=False),\n",
    "    'No Preprocessing': lambda x: x,\n",
    "    'Advanced (Stem+Stop+Emoticon)': lambda x: preprocess_text_advanced(x, use_stopwords=True, use_stemming=True),\n",
    "    'Advanced (Stop+Emoticon)': lambda x: preprocess_text_advanced(x, use_stopwords=True, use_stemming=False),\n",
    "    'Advanced (Stem+Emoticon)': lambda x: preprocess_text_advanced(x, use_stopwords=False, use_stemming=True),\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SVM': LinearSVC()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for pp_name, pp_func in preprocessing_options.items():\n",
    "    print(f'--- Preprocessing: {pp_name} ---')\n",
    "    tfidf_vectorizer = TfidfVectorizer(preprocessor=pp_func)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        report = classification_report(y_test, y_pred, target_names=label_map.keys(), output_dict=True, zero_division=0)\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Preprocessing': pp_name,\n",
    "            'Accuracy': report['accuracy'],\n",
    "            'F1-Score (Weighted)': report['weighted avg']['f1-score']\n",
    "        })\n",
    "        print(f'\\n--- {model_name} with {pp_name} ---')\n",
    "        print(classification_report(y_test, y_pred, target_names=label_map.keys(), zero_division=0))\n",
    "\n",
    "results_df_tfidf = pd.DataFrame(results)\n",
    "print(results_df_tfidf.sort_values(by='Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedding-based Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Load Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load local BERT model\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('./indonesia-bert-sentiment-classification')\n",
    "bert_model = BertModel.from_pretrained('./indonesia-bert-sentiment-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained FastText model\n",
    "fasttext_model = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Create Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "def get_fasttext_embedding(text, model):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Create embeddings for the datasets\n",
    "X_train_bert = np.array([get_bert_embedding(text, bert_tokenizer, bert_model) for text in X_train])\n",
    "X_test_bert = np.array([get_bert_embedding(text, bert_tokenizer, bert_model) for text in X_test])\n",
    "\n",
    "X_train_ft = np.array([get_fasttext_embedding(text, fasttext_model) for text in X_train])\n",
    "X_test_ft = np.array([get_fasttext_embedding(text, fasttext_model) for text in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Train and Evaluate Models on Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression with BERT Embeddings ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.76      0.82      0.79       354\n",
      "     neutral       0.65      0.61      0.63       147\n",
      "    negative       0.68      0.60      0.64       157\n",
      "\n",
      "    accuracy                           0.72       658\n",
      "   macro avg       0.70      0.68      0.68       658\n",
      "weighted avg       0.72      0.72      0.72       658\n",
      "\n",
      "\n",
      "--- SVM with BERT Embeddings ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.76      0.79      0.78       354\n",
      "     neutral       0.64      0.62      0.63       147\n",
      "    negative       0.63      0.59      0.61       157\n",
      "\n",
      "    accuracy                           0.71       658\n",
      "   macro avg       0.68      0.67      0.67       658\n",
      "weighted avg       0.70      0.71      0.70       658\n",
      "\n",
      "\n",
      "--- Logistic Regression with FastText Embeddings ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.56      0.97      0.71       354\n",
      "     neutral       0.66      0.20      0.30       147\n",
      "    negative       0.33      0.01      0.02       157\n",
      "\n",
      "    accuracy                           0.57       658\n",
      "   macro avg       0.52      0.39      0.35       658\n",
      "weighted avg       0.53      0.57      0.46       658\n",
      "\n",
      "\n",
      "--- SVM with FastText Embeddings ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.59      0.94      0.73       354\n",
      "     neutral       0.65      0.33      0.43       147\n",
      "    negative       0.50      0.06      0.11       157\n",
      "\n",
      "    accuracy                           0.59       658\n",
      "   macro avg       0.58      0.44      0.42       658\n",
      "weighted avg       0.58      0.59      0.51       658\n",
      "\n",
      "                 Model        Preprocessing  Accuracy  F1-Score (Weighted)\n",
      "0  Logistic Regression      BERT Embeddings  0.720365             0.717266\n",
      "1                  SVM      BERT Embeddings  0.705167             0.703479\n",
      "3                  SVM  FastText Embeddings  0.594225             0.514314\n",
      "2  Logistic Regression  FastText Embeddings  0.568389             0.457338\n"
     ]
    }
   ],
   "source": [
    "embedding_results = []\n",
    "embedding_data = {\n",
    "    'BERT': (X_train_bert, X_test_bert),\n",
    "    'FastText': (X_train_ft, X_test_ft)\n",
    "}\n",
    "\n",
    "embedding_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=2000),\n",
    "    'SVM': LinearSVC(max_iter=2000)\n",
    "}\n",
    "\n",
    "for emb_name, (X_train_emb, X_test_emb) in embedding_data.items():\n",
    "    for model_name, model in embedding_models.items():\n",
    "        print(f'\\n--- {model_name} with {emb_name} Embeddings ---')\n",
    "        model.fit(X_train_emb, y_train)\n",
    "        y_pred = model.predict(X_test_emb)\n",
    "        report = classification_report(y_test, y_pred, target_names=label_map.keys(), output_dict=True, zero_division=0)\n",
    "        embedding_results.append({\n",
    "            'Model': model_name,\n",
    "            'Preprocessing': f'{emb_name} Embeddings',\n",
    "            'Accuracy': report['accuracy'],\n",
    "            'F1-Score (Weighted)': report['weighted avg']['f1-score']\n",
    "        })\n",
    "        print(classification_report(y_test, y_pred, target_names=label_map.keys(), zero_division=0))\n",
    "\n",
    "results_df_emb = pd.DataFrame(embedding_results)\n",
    "print(results_df_emb.sort_values(by='Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- All Results ---\n",
      "                  Model                    Preprocessing  Accuracy  \\\n",
      "5                   SVM         Stemming Only (Sastrawi)  0.772036   \n",
      "20                  SVM         Advanced (Stem+Emoticon)  0.762918   \n",
      "14                  SVM    Advanced (Stem+Stop+Emoticon)  0.759878   \n",
      "2                   SVM  Stemming + Stopwords (Sastrawi)  0.755319   \n",
      "17                  SVM         Advanced (Stop+Emoticon)  0.752280   \n",
      "8                   SVM        Stopwords Only (Sastrawi)  0.750760   \n",
      "11                  SVM                 No Preprocessing  0.747720   \n",
      "18  Logistic Regression         Advanced (Stem+Emoticon)  0.746201   \n",
      "3   Logistic Regression         Stemming Only (Sastrawi)  0.735562   \n",
      "15  Logistic Regression         Advanced (Stop+Emoticon)  0.735562   \n",
      "12  Logistic Regression    Advanced (Stem+Stop+Emoticon)  0.734043   \n",
      "0   Logistic Regression  Stemming + Stopwords (Sastrawi)  0.729483   \n",
      "6   Logistic Regression        Stopwords Only (Sastrawi)  0.729483   \n",
      "9   Logistic Regression                 No Preprocessing  0.720365   \n",
      "21  Logistic Regression                  BERT Embeddings  0.720365   \n",
      "22                  SVM                  BERT Embeddings  0.705167   \n",
      "1           Naive Bayes  Stemming + Stopwords (Sastrawi)  0.627660   \n",
      "7           Naive Bayes        Stopwords Only (Sastrawi)  0.624620   \n",
      "13          Naive Bayes    Advanced (Stem+Stop+Emoticon)  0.620061   \n",
      "4           Naive Bayes         Stemming Only (Sastrawi)  0.617021   \n",
      "16          Naive Bayes         Advanced (Stop+Emoticon)  0.613982   \n",
      "10          Naive Bayes                 No Preprocessing  0.606383   \n",
      "19          Naive Bayes         Advanced (Stem+Emoticon)  0.604863   \n",
      "24                  SVM              FastText Embeddings  0.594225   \n",
      "23  Logistic Regression              FastText Embeddings  0.568389   \n",
      "\n",
      "    F1-Score (Weighted)  \n",
      "5              0.767013  \n",
      "20             0.758649  \n",
      "14             0.754059  \n",
      "2              0.749321  \n",
      "17             0.744706  \n",
      "8              0.743329  \n",
      "11             0.739591  \n",
      "18             0.730664  \n",
      "3              0.719815  \n",
      "15             0.717479  \n",
      "12             0.717980  \n",
      "0              0.711713  \n",
      "6              0.713021  \n",
      "9              0.701620  \n",
      "21             0.717266  \n",
      "22             0.703479  \n",
      "1              0.553370  \n",
      "7              0.545480  \n",
      "13             0.538896  \n",
      "4              0.532921  \n",
      "16             0.527448  \n",
      "10             0.513085  \n",
      "19             0.512103  \n",
      "24             0.514314  \n",
      "23             0.457338  \n"
     ]
    }
   ],
   "source": [
    "final_results = pd.concat([results_df_tfidf, results_df_emb], ignore_index=True)\n",
    "print(\"--- All Results ---\")\n",
    "print(final_results.sort_values(by='Accuracy', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
